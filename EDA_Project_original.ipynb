{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml.html as lh\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import json\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.firefox_profile import FirefoxProfile\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Wuzzuf sitemap URL\n",
    "sitemap_url = \"https://wuzzuf.net/sitemap-job-1.xml\"\n",
    "response = requests.get(sitemap_url)\n",
    "\n",
    "# Parse the XML\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"xml\")\n",
    "    urls = [loc.text for loc in soup.find_all(\"loc\")]\n",
    "        \n",
    "else:\n",
    "    print(\"Failed to fetch the sitemap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8595"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "working_hours = []\n",
    "working_place = []\n",
    "company = []\n",
    "location = []\n",
    "post_date = []\n",
    "num_of_applicants = []\n",
    "num_of_positions = []\n",
    "experience = []\n",
    "career_level = []\n",
    "education = []\n",
    "salary = []\n",
    "job_category = []\n",
    "skills = []\n",
    "job_description = []\n",
    "job_requirements = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Backend Developer\n",
      "Full Time\n",
      "Hybrid\n",
      "RocketDevs\n",
      "Cairo, Egypt\n",
      "Posted 27 days ago\n",
      "12\n",
      "1 open position\n",
      "More Than 5 Years\n",
      "Experienced (Non-Manager)\n",
      "Bachelor'S Degree\n",
      "Confidential\n",
      "IT/Software Development\n",
      "['Software Development', 'Ruby', 'Ruby on Rails', 'Infrastructure Engineering', 'Computer Science', 'Software Engineering', 'Web Development', 'API']\n"
     ]
    }
   ],
   "source": [
    "print(driver.find_elements(By.XPATH, \"//section/div/h1\")[0].text)\n",
    "print(driver.find_elements(By.XPATH, \"//section/div/div/div/a/span\")[0].text)\n",
    "print(driver.find_elements(By.XPATH, \"//section/div/div/a/span\")[0].text)\n",
    "print(driver.find_elements(By.XPATH, \"//strong/div/a\")[1].text)\n",
    "print(driver.find_elements(By.XPATH, \"//strong\")[1].text.split('-')[-1].strip())\n",
    "print(driver.find_elements(By.XPATH, \"//section/div/span\")[0].text)\n",
    "print(driver.find_elements(By.XPATH, \"//section/div/div/div/strong\")[0].text)\n",
    "print(driver.find_elements(By.XPATH, \"//div/div/span/span\")[1].text)\n",
    "print(driver.find_elements(By.XPATH, \"//main//section/div/span/span\")[0].text)\n",
    "print(driver.find_elements(By.XPATH, \"//main//section/div/span/span\")[1].text)\n",
    "print(driver.find_elements(By.XPATH, \"//main//section/div/span/span\")[2].text)\n",
    "print(driver.find_elements(By.XPATH, \"//main//section/div/span/span\")[3].text)\n",
    "print(driver.find_elements(By.XPATH, \"//div/ul/li/a/span\")[0].text)\n",
    "print([i.text for i in driver.find_elements(By.XPATH, \"//div/a/span/span/span\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
