{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml.html as lh\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import json\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.firefox_profile import FirefoxProfile\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Wuzzuf sitemap URL\n",
    "sitemap_url = \"https://wuzzuf.net/sitemap-job-1.xml\"\n",
    "response = requests.get(sitemap_url)\n",
    "\n",
    "# Parse the XML\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"xml\")\n",
    "    urls = [loc.text for loc in soup.find_all(\"loc\")]\n",
    "        \n",
    "else:\n",
    "    print(\"Failed to fetch the sitemap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "working_hours = []\n",
    "working_place = []\n",
    "company = []\n",
    "location = []\n",
    "post_date = []\n",
    "num_of_applicants = []\n",
    "num_of_positions = []\n",
    "experience = []\n",
    "career_level = []\n",
    "education = []\n",
    "salary = []\n",
    "job_category = []\n",
    "skills = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through URLs and collect data\n",
    "for url in urls[:5]:\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the page to load by waiting for a specific element to be present\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//section/div/h1\")))\n",
    "        \n",
    "        # Append data to lists with individual error handling\n",
    "        try:\n",
    "            title.append(driver.find_elements(By.XPATH, \"//section/div/h1\")[0].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting title from {url}: {str(e)}\")\n",
    "            title.append(None)\n",
    "        \n",
    "        try:\n",
    "            working_hours.append(driver.find_elements(By.XPATH, \"//section/div/div/div/a/span\")[0].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting working hours from {url}: {str(e)}\")\n",
    "            working_hours.append(None)\n",
    "        \n",
    "        try:\n",
    "            working_place.append(driver.find_elements(By.XPATH, \"//section/div/div/a/span\")[0].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting working place from {url}: {str(e)}\")\n",
    "            working_place.append(None)\n",
    "        \n",
    "        try:\n",
    "            company.append(driver.find_elements(By.XPATH, \"//strong/div/a\")[1].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting company from {url}: {str(e)}\")\n",
    "            company.append(None)\n",
    "        \n",
    "        try:\n",
    "            location.append(driver.find_elements(By.XPATH, \"//strong\")[1].text.split('-')[-1].strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting location from {url}: {str(e)}\")\n",
    "            location.append(None)\n",
    "        \n",
    "        try:\n",
    "            post_date.append(driver.find_elements(By.XPATH, \"//section/div/span\")[0].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting post date from {url}: {str(e)}\")\n",
    "            post_date.append(None)\n",
    "        \n",
    "        try:\n",
    "            num_of_applicants.append(driver.find_elements(By.XPATH, \"//section/div/div/div/strong\")[0].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting number of applicants from {url}: {str(e)}\")\n",
    "            num_of_applicants.append(None)\n",
    "        \n",
    "        try:\n",
    "            num_of_positions.append(driver.find_elements(By.XPATH, \"//div/div/span/span\")[1].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting number of positions from {url}: {str(e)}\")\n",
    "            num_of_positions.append(None)\n",
    "        \n",
    "        try:\n",
    "            experience.append(driver.find_elements(By.XPATH, \"//main//section/div/span/span\")[0].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting experience from {url}: {str(e)}\")\n",
    "            experience.append(None)\n",
    "        \n",
    "        try:\n",
    "            career_level.append(driver.find_elements(By.XPATH, \"//main//section/div/span/span\")[1].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting career level from {url}: {str(e)}\")\n",
    "            career_level.append(None)\n",
    "        \n",
    "        try:\n",
    "            education.append(driver.find_elements(By.XPATH, \"//main//section/div/span/span\")[2].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting education from {url}: {str(e)}\")\n",
    "            education.append(None)\n",
    "        \n",
    "        try:\n",
    "            salary.append(driver.find_elements(By.XPATH, \"//main//section/div/span/span\")[3].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting salary from {url}: {str(e)}\")\n",
    "            salary.append(None)\n",
    "        \n",
    "        try:\n",
    "            job_category.append(driver.find_elements(By.XPATH, \"//div/ul/li/a/span\")[0].text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting job category from {url}: {str(e)}\")\n",
    "            job_category.append(None)\n",
    "        \n",
    "        try:\n",
    "            skills.append([i.text for i in driver.find_elements(By.XPATH, \"//div/a/span/span/span\")])\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting skills from {url}: {str(e)}\")\n",
    "            skills.append(None)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {str(e)}\")\n",
    "\n",
    "# Create DataFrame\n",
    "jobs_df = pd.DataFrame({\n",
    "    'Title': title,\n",
    "    'Working_Hours': working_hours,\n",
    "    'Working_Place': working_place,\n",
    "    'Company': company,\n",
    "    'Location': location,\n",
    "    'Post_Date': post_date,\n",
    "    'Number_of_Applicants': num_of_applicants,\n",
    "    'Number_of_Positions': num_of_positions,\n",
    "    'Experience': experience,\n",
    "    'Career_Level': career_level,\n",
    "    'Education': education,\n",
    "    'Salary': salary,\n",
    "    'Job_Category': job_category,\n",
    "    'Skills': skills\n",
    "})\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.to_csv(\"jobs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
